test:
  service: Disk
  root: <%= Rails.root.join("tmp/storage") %>

local:
  service: Disk
  root: <%= Rails.root.join("storage") %>

amazon:
  service: S3
  access_key_id: <%= ENV.fetch('AWS_ACCESS_KEY_ID', '') %>
  secret_access_key: <%= ENV.fetch('AWS_SECRET_ACCESS_KEY', '') %>
  region: <%= ENV.fetch('AWS_REGION', 'us-east-1') %>
  bucket: <%= ENV.fetch('ACTIVE_STORAGE_BUCKET', "#{ENV['AWS_CLIENT_NAME']}-#{ENV['AWS_APP_NAME']}-#{Rails.env}-files") %>
  http_open_timeout: 60
  http_read_timeout: 60
  retry_limit: 5

# Note, you'll probably need to run the following before the new file uploads will work
# Depending on when your environment was setup, some or all of these may have already happened
# mkdir -p ~/minio/data
# mkdir -p ~/.minio/certs
# Copy certs (replace source directory if yours is different)
# cp ~/hmis-warehouse/docker/nginx-proxy/certs/dev.test.crt ~/.minio/certs/public.crt
# cp ~/hmis-warehouse/docker/nginx-proxy/certs/dev.test.key ~/.minio/certs/private.key

# sudo cp /vagrant/hmis-warehouse/docker/nginx-proxy/certs/dev.test.crt /usr/local/share/ca-certificates
# sudo update-ca-certificates

# dcr console
# c = Aws::S3::Client.new(endpoint: 'http://s3.dev.test:9000', region: 'us-east-1', access_key_id: 'local_access_key', secret_access_key: 'local_secret_key', force_path_style: true)
# c.create_bucket(bucket: ENV.fetch('ACTIVE_STORAGE_BUCKET', 'active-storage'))
minio:
  service: S3
  force_path_style: true # don't force dns hoop jumping
  endpoint: <%= ENV.fetch('MINIO_ENDPOINT', "https://s3.dev.test:9000") %>
  access_key_id:  local_access_key
  secret_access_key: local_secret_key
  region: us-east-1
  bucket: <%= ENV.fetch('ACTIVE_STORAGE_BUCKET', 'active-storage') %>
  http_open_timeout: 30
  http_read_timeout: 30
  retry_limit: 5
